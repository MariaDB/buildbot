# -*- python -*-
# ex: set filetype=python:

from buildbot.plugins import *
from buildbot.process.properties import Property, Properties
from buildbot.steps.shell import ShellCommand, Compile, Test, SetPropertyFromCommand
from buildbot.steps.mtrlogobserver import MTR, MtrLogObserver
from buildbot.steps.source.github import GitHub
from buildbot.process.remotecommand import RemoteCommand
from datetime import timedelta
from twisted.internet import defer

import docker
import os
import sys

sys.setrecursionlimit(10000)

sys.path.insert(0, "/srv/buildbot/master")

from constants import *
from utils import *
from locks import *
from schedulers_definition import *
from common_factories import *

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

# Load the slave, database passwords and 3rd-party tokens from an external private file, so
# that the rest of the configuration can be public.
config = {"private": {}}
exec(open("../master-private.cfg").read(), config, {})

####### BUILDBOT SERVICES

# 'services' is a list of BuildbotService items like reporter targets. The
# status of each build will be pushed to these targets. buildbot/reporters/*.py
# has a variety to choose from, like IRC bots.


c["services"] = []
context = util.Interpolate("buildbot/%(prop:buildername)s")
gs = reporters.GitHubStatusPush(
    token=config["private"]["gh_mdbci"]["access_token"],
    context=context,
    startDescription="Build started.",
    endDescription="Build done.",
    verbose=True,
    builders=github_status_builders,
)
c["services"].append(gs)

####### PROJECT IDENTITY

# the 'title' string will appear at the top of this buildbot installation's
# home pages (linked to the 'titleURL').
c["title"] = os.getenv("TITLE", default="MariaDB CI")
c["titleURL"] = os.getenv("TITLE_URL", default="https://github.com/MariaDB/server")

# the 'buildbotURL' string should point to the location where the buildbot's
# internal web server is visible. This typically uses the port number set in
# the 'www' entry below, but with an externally-visible host name which the
# buildbot cannot figure out without some help.
c["buildbotURL"] = os.getenv("BUILDMASTER_URL", default="https://buildbot.mariadb.org/")

# 'protocols' contains information about protocols which master will use for
# communicating with workers. You must define at least 'port' option that workers
# could connect to your master with this protocol.
# 'port' must match the value configured into the workers (with their
# --master option)
port = int(os.getenv("PORT", default="9994"))
c["protocols"] = {"pb": {"port": port}}

####### DB URL

c["db"] = {
    # This specifies what database buildbot uses to store its state.
    "db_url": config["private"]["db_url"]
}

mtrDbPool = util.EqConnectionPool(
    "MySQLdb",
    config["private"]["db_host"],
    config["private"]["db_user"],
    config["private"]["db_password"],
    config["private"]["db_mtr_db"],
)

####### Disable net usage reports from being sent to buildbot.net
c["buildbotNetUsageData"] = None

####### SCHEDULERS

# Configure the Schedulers, which decide how to react to incoming changes.
c["schedulers"] = getSchedulers()

####### WORKERS

# The 'workers' list defines the set of recognized workers. Each element is
# a Worker object, specifying a unique worker name and password.  The same
# worker name and password must be configured on the worker.
c["workers"] = []

# Docker workers
FQDN = os.getenv("BUILDMASTER_WG_IP", default="100.64.100.1")
MASTER_PACKAGES = os.getenv(
    "MASTER_PACKAGES_DIR", default="/mnt/autofs/master_packages"
)

## hz-bbw2-docker
c["workers"].append(
    worker.DockerLatentWorker(
        "hz-bbw1-docker-tarball-debian-10",
        None,
        docker_host=config["private"]["docker_workers"]["hz-bbw1-docker"],
        image="quay.io/mariadb-foundation/bb-worker:debian10",
        followStartupLogs=False,
        autopull=True,
        alwaysPull=True,
        masterFQDN=FQDN,
        hostconfig={"shm_size": "1G"},
        volumes=[MASTER_PACKAGES + "/:/packages"],
        max_builds=1,
        build_wait_timeout=0,
        properties={"jobs": 4, "save_packages": True},
    )
)

c["workers"].append(
    worker.DockerLatentWorker(
        "hz-bbw4-docker-tarball-debian-10",
        None,
        docker_host=config["private"]["docker_workers"]["hz-bbw4-docker"],
        image="quay.io/mariadb-foundation/bb-worker:debian10",
        followStartupLogs=False,
        autopull=True,
        alwaysPull=True,
        masterFQDN=FQDN,
        hostconfig={"shm_size": "1G"},
        volumes=[MASTER_PACKAGES + "/:/packages"],
        max_builds=1,
        build_wait_timeout=0,
        properties={"jobs": 4, "save_packages": True},
    )
)

workers = {}


def addWorker(
    worker_name_prefix,
    worker_id,
    worker_type,
    dockerfile,
    jobs=5,
    save_packages=False,
    shm_size="15G",
):
    name, instance = createWorker(
        worker_name_prefix,
        worker_id,
        worker_type,
        dockerfile,
        jobs,
        save_packages,
        shm_size,
    )

    if name[0] not in workers:
        workers[name[0]] = [name[1]]
    else:
        workers[name[0]].append(name[1])

    c["workers"].append(instance)


for w_name in ["hz-bbw"]:
    jobs = 7
    for i in [1, 4]:
        addWorker(
            w_name,
            i,
            "-centos-7",
            "quay.io/mariadb-foundation/bb-worker:centos7",
            jobs=jobs,
            save_packages=True,
        )
        addWorker(
            w_name,
            i,
            "-debian-10",
            "quay.io/mariadb-foundation/bb-worker:debian10",
            jobs=jobs,
            save_packages=True,
        )
        addWorker(
            w_name,
            i,
            "-debian-10-debug-embed",
            "quay.io/mariadb-foundation/bb-worker:debian10",
            jobs=14,
            save_packages=False,
        )
        addWorker(
            w_name,
            i,
            "-debian-11-debug-ps-embed",
            "quay.io/mariadb-foundation/bb-worker:debian11",
            jobs=14,
            save_packages=False,
        )
        addWorker(
            w_name,
            i,
            "-fedora-38",
            "quay.io/mariadb-foundation/bb-worker:fedora38",
            jobs=jobs,
            save_packages=True,
        )
        addWorker(
            w_name,
            i,
            "-ubuntu-2004-clang",
            "vladbogo/bb:amd64-ubuntu-2004-clang",
            jobs=jobs,
            save_packages=True,
        )
        addWorker(
            w_name,
            i,
            "-ubuntu-2004-debug",
            "quay.io/mariadb-foundation/bb-worker:ubuntu20.04",
            jobs=14,
            save_packages=True,
        )
        addWorker(
            w_name,
            i,
            "-ubuntu-2204-debug-ps",
            "quay.io/mariadb-foundation/bb-worker:ubuntu22.04",
            jobs=14,
            save_packages=False,
        )

####### FACTORY CODE

f_quick_build = getQuickBuildFactory(mtrDbPool)
f_last_n_failed = getLastNFailedBuildsFactory(mtrDbPool)

## f_tarball - create source tarball
f_tarball = util.BuildFactory()
f_tarball.addStep(
    steps.SetProperty(
        property="dockerfile",
        value=util.Interpolate("%(kw:url)s", url=dockerfile),
        description="dockerfile",
    )
)
f_tarball.addStep(
    steps.ShellCommand(command=["echo", " revision: ", util.Property("revision")])
)
f_tarball.addStep(
    steps.GitHub(
        repourl=util.Property("repository"),
        mode="full",
        method="clobber",
        workdir="build/server",
        shallow=True,
        submodules=True,
    )
)
f_tarball.addStep(
    steps.Compile(
        command=["cmake", "../server"], workdir="build/mkdist", description="cmake"
    )
)
f_tarball.addStep(
    steps.Compile(
        command=["make", "dist"], workdir="build/mkdist", description="make dist"
    )
)
f_tarball.addStep(
    steps.SetPropertyFromCommand(
        property="mariadb_version",
        command="basename mariadb-*.tar.gz .tar.gz",
        workdir="build/mkdist",
    )
)
f_tarball.addStep(
    steps.SetPropertyFromCommand(
        property="master_branch",
        command=util.Interpolate(
            "echo "
            + "%(prop:mariadb_version)s"
            + " | cut -d'-' -f 2 | cut -d'.' -f 1,2"
        ),
    )
)
f_tarball.addStep(
    steps.ShellCommand(
        command=util.Interpolate("mkdir -p %(prop:buildnumber)s/logs"),
        workdir="build/mkdist",
    )
)
f_tarball.addStep(
    steps.ShellCommand(
        command=util.Interpolate(
            "sha256sum %(prop:mariadb_version)s"
            + ".tar.gz >> "
            + " %(prop:buildnumber)s"
            + "/sha256sums.txt"
            + " && mv %(prop:mariadb_version)s"
            + ".tar.gz"
            + " %(prop:buildnumber)s"
        ),
        workdir="build/mkdist",
    )
)
f_tarball.addStep(
    steps.SetPropertyFromCommand(
        command="ls -1 *.tar.gz",
        extract_fn=ls2list,
        workdir=util.Interpolate("build/mkdist/" + "%(prop:buildnumber)s"),
    )
)
f_tarball.addStep(
    steps.ShellCommand(
        name="save_packages",
        haltOnFailure=True,
        command=util.Interpolate(
            "cp -r "
            + "%(prop:builddir)s"
            + "/build/mkdist/"
            + "%(prop:buildnumber)s"
            + " /packages && sync /packages/"
            + "%(prop:buildnumber)s"
        ),
    )
)
f_tarball.addStep(
    steps.Trigger(
        schedulerNames=["s_protected_branches"],
        waitForFinish=False,
        updateSourceStamp=False,
        doStepIf=waitIfStaging,
        set_properties={
            "tarbuildnum": Property("buildnumber"),
            "mariadb_version": Property("mariadb_version"),
            "master_branch": Property("master_branch"),
        },
    )
)
f_tarball.addStep(
    steps.Trigger(
        schedulerNames=["s_upstream_all"],
        waitForFinish=False,
        updateSourceStamp=False,
        set_properties={
            "tarbuildnum": Property("buildnumber"),
            "mariadb_version": Property("mariadb_version"),
            "master_branch": Property("master_branch"),
        },
    )
)
f_tarball.addStep(
    steps.SetPropertyFromCommand(
        command=util.Interpolate("echo " + "prot-" + "%(prop:master_branch)s"),
        property="master_staging_branch",
    )
)
f_tarball.addStep(
    steps.ShellSequence(
        commands=[
            util.ShellArg(
                command="git config --global user.email '"
                + config["private"]["gh_mdbci"]["email"]
                + "'"
            ),
            util.ShellArg(
                command="git config --global user.name '"
                + config["private"]["gh_mdbci"]["name"]
                + "'"
            ),
            util.ShellArg(
                command="git remote set-url origin https://"
                + config["private"]["gh_mdbci"]["push_access_token"]
                + ":x-oauth-basic@github.com/cvicentiu/server"
            ),
            util.ShellArg(
                command=util.Interpolate(
                    "git fetch origin %(prop:master_staging_branch)s && git branch %(prop:master_staging_branch)s FETCH_HEAD && git checkout %(prop:master_staging_branch)s && git checkout %(prop:branch)s && git pull --unshallow"
                ),
                logfile="rebase",
            ),
            util.ShellArg(
                command=[
                    "bash",
                    "-xc",
                    util.Interpolate(
                        "if git checkout %(prop:master_staging_branch)s && git merge --ff-only %(prop:branch)s; then git push --set-upstream origin %(prop:master_staging_branch)s; else  if git checkout %(prop:branch)s && [[ $(git --no-pager log --merges %(prop:master_staging_branch)s..%(prop:branch)s | wc -l) -ne 0 ]]; then exit 1; else git rebase %(prop:master_staging_branch)s && git push --force; fi fi"
                    ),
                ],
                logfile="rebase",
            ),
        ],
        workdir="build/server",
        haltOnFailure="true",
        doStepIf=lambda step: isStagingBranch(step),
    )
)
# f_tarball.addStep(steps.ShellSequence( commands=[
#    util.ShellArg(command=util.Interpolate("git checkout " + "%(prop:staging_branch)s"), logfile="rebase"),
#    util.ShellArg(command=util.Interpolate("git merge %(prop:branch)s"), logfile="rebase")], workdir="build/server", haltOnFailure="true", doStepIf=ifStagingSucceeding))
f_tarball.addStep(
    steps.ShellCommand(
        name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True
    )
)

####### BUILDERS LIST
protected_branches_mtr_additional_args = '--suite=main,spider,spider/bg,spider/bugfix,spider/feature,spider/regression/e1121,spider/regression/e112122 --skip-test="^stack_crash$|^float$|^derived_split_innodb$|^mysql_client_test$|^kill$|^processlist_not_embedded$|^sp-big$"'

c["builders"] = []

c["builders"].append(
    util.BuilderConfig(
        name="tarball-docker",
        workernames=[
            "hz-bbw1-docker-tarball-debian-10",
            "hz-bbw4-docker-tarball-debian-10",
        ],
        tags=["tar", "bake"],
        collapseRequests=True,
        nextBuild=nextBuild,
        factory=f_tarball,
    )
)

c["builders"].append(
    util.BuilderConfig(
        name="amd64-ubuntu-2004-debug",
        workernames=workers["x64-bbw-docker-ubuntu-2004-debug"],
        tags=["Ubuntu", "quick", "gcc", "debug", "protected"],
        collapseRequests=True,
        nextBuild=nextBuild,
        canStartBuild=canStartBuild,
        locks=getLocks,
        properties={
            "build_type": "Debug",
            "additional_args": "-DWITH_DBUG_TRACE=OFF -DHAVE_valgrind",
            "mtr_additional_args": '--skip-test="main\.show_analyze_json"',
        },
        factory=f_quick_build,
    )
)

c["builders"].append(
    util.BuilderConfig(
        name="amd64-ubuntu-2204-debug-ps",
        workernames=workers["x64-bbw-docker-ubuntu-2204-debug-ps"],
        tags=["Ubuntu", "quick", "gcc", "debug", "protected"],
        collapseRequests=True,
        nextBuild=nextBuild,
        canStartBuild=canStartBuild,
        locks=getLocks,
        properties={
            "build_type": "Debug",
            "additional_args": "-DWITH_DBUG_TRACE=OFF -DHAVE_valgrind",
            "create_package": " ",
            "mtr_additional_args": '--ps-protocol --skip-test="main\.show_analyze_json"',
        },
        factory=f_quick_build,
    )
)

c["builders"].append(
    util.BuilderConfig(
        name="amd64-debian-10-debug-embedded",
        workernames=workers["x64-bbw-docker-debian-10-debug-embed"],
        tags=["Ubuntu", "quick", "gcc", "debug", "protected"],
        collapseRequests=True,
        nextBuild=nextBuild,
        canStartBuild=canStartBuild,
        locks=getLocks,
        properties={
            "build_type": "Debug",
            "create_package": " ",
            "additional_args": "-DWITH_EMBEDDED_SERVER:BOOL=ON -DWITH_DBUG_TRACE=OFF",
            "mtr_additional_args": '--embedded --skip-test="main\.show_analyze_json"',
        },
        factory=f_quick_build,
    )
)

c["builders"].append(
    util.BuilderConfig(
        name="amd64-debian-11-debug-ps-embedded",
        workernames=workers["x64-bbw-docker-debian-11-debug-ps-embed"],
        tags=["Ubuntu", "quick", "gcc", "debug", "protected"],
        collapseRequests=True,
        nextBuild=nextBuild,
        canStartBuild=canStartBuild,
        locks=getLocks,
        properties={
            "build_type": "Debug",
            "create_package": " ",
            "additional_args": "-DWITH_EMBEDDED_SERVER:BOOL=ON -DWITH_DBUG_TRACE=OFF",
            "mtr_additional_args": '--ps-protocol --embedded --skip-test="main\.show_analyze_json"',
        },
        factory=f_quick_build,
    )
)

c["builders"].append(
    util.BuilderConfig(
        name="amd64-debian-10",
        workernames=workers["x64-bbw-docker-debian-10"],
        tags=["Debian", "quick", "gcc", "protected"],
        collapseRequests=True,
        nextBuild=nextBuild,
        canStartBuild=canStartBuild,
        locks=getLocks,
        properties={"mtr_additional_args": protected_branches_mtr_additional_args},
        factory=f_last_n_failed,
    )
)

c["builders"].append(
    util.BuilderConfig(
        name="amd64-fedora-38",
        workernames=workers["x64-bbw-docker-fedora-38"],
        tags=["Fedora", "quick", "gcc", "protected"],
        collapseRequests=True,
        nextBuild=nextBuild,
        canStartBuild=canStartBuild,
        locks=getLocks,
        properties={"mtr_additional_args": protected_branches_mtr_additional_args},
        factory=f_last_n_failed,
    )
)

c["builders"].append(
    util.BuilderConfig(
        name="amd64-centos-7",
        workernames=workers["x64-bbw-docker-centos-7"],
        tags=["Centos", "quick", "gcc", "protected"],
        collapseRequests=True,
        nextBuild=nextBuild,
        canStartBuild=canStartBuild,
        locks=getLocks,
        properties={"mtr_additional_args": protected_branches_mtr_additional_args},
        factory=f_quick_build,
    )
)

c["logEncoding"] = "utf-8"

c["multiMaster"] = True

c["mq"] = {  # Need to enable multimaster aware mq. Wamp is the only option for now.
    "type": "wamp",
    "router_url": os.getenv("MQ_ROUTER_URL", default="ws://localhost:8085/ws"),
    "realm": "realm1",
    # valid are: none, critical, error, warn, info, debug, trace
    "wamp_debug_level": "info",
}
