# -*- python -*-
# ex: set filetype=python:

from buildbot.plugins import *
from buildbot.process.properties import Property, Properties
from buildbot.steps.shell import ShellCommand, Compile, Test, SetPropertyFromCommand
from buildbot.steps.mtrlogobserver import MTR, MtrLogObserver
from buildbot.steps.source.github import GitHub
from buildbot.process.remotecommand import RemoteCommand
from twisted.internet import defer
import sys
import os
import docker
from datetime import timedelta

sys.setrecursionlimit(10000)

sys.path.append(os.getcwd() + "/..")
from constants import *
from utils import *

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

# Load the slave, database passwords and 3rd-party tokens from an external private file, so
# that the rest of the configuration can be public.
config = {"private": {}}
exec(open("../master-private.cfg").read(), config, {})

####### PROJECT IDENTITY

# the 'title' string will appear at the top of this buildbot installation's
# home pages (linked to the 'titleURL').
c["title"] = os.getenv("TITLE", default="MariaDB CI")
c["titleURL"] = os.getenv("TITLE_URL", default="https://github.com/MariaDB/server")

# the 'buildbotURL' string should point to the location where the buildbot's
# internal web server is visible. This typically uses the port number set in
# the 'www' entry below, but with an externally-visible host name which the
# buildbot cannot figure out without some help.
c["buildbotURL"] = os.getenv("BUILDMASTER_URL", default="https://buildbot.mariadb.org/")

# 'protocols' contains information about protocols which master will use for
# communicating with workers. You must define at least 'port' option that workers
# could connect to your master with this protocol.
# 'port' must match the value configured into the workers (with their
# --master option)
port = int(os.getenv("PORT", default="9991"))
c["protocols"] = {"pb": {"port": port}}

####### DB URL

c["db"] = {
    # This specifies what database buildbot uses to store its state.
    "db_url": config["private"]["db_url"]
}

####### Disable net usage reports from being sent to buildbot.net
c["buildbotNetUsageData"] = None

####### SCHEDULERS

# Configure the Schedulers, which decide how to react to incoming changes.

branches_main = ["mariadb-3.x", "mariadb-4.x", "bb-*"]
savedPackageBranches = ["mariadb-3.x", "mariadb-4.x", "bb-*"]

# git branch filter using fnmatch
import fnmatch


def upstream_branch_fn(branch):
    return (
        branch in branches_main
        or fnmatch.fnmatch(branch, "mariadb-3.x")
        or fnmatch.fnmatch(branch, "mariadb-4.x")
        or fnmatch.fnmatch(branch, "bb-*")
        or fnmatch.fnmatch(branch, "refs/pull/*")
    )


def fnmatch_any(s, list_of_patterns):
    return any(fnmatch.fnmatch(s, p) for p in list_of_patterns)


c["schedulers"] = []

schedulerTrigger = schedulers.AnyBranchScheduler(
    name="s_upstream_galera",
    change_filter=util.ChangeFilter(
        repository="https://github.com/MariaDB/galera", branch_fn=upstream_branch_fn
    ),
    treeStableTimer=60,
    builderNames=builders_galera,
)
c["schedulers"].append(schedulerTrigger)

####### WORKERS

# The 'workers' list defines the set of recognized workers. Each element is
# a Worker object, specifying a unique worker name and password.  The same
# worker name and password must be configured on the worker.
c["workers"] = []

# Docker workers

workers = {}


def addWorker(
    worker_name_prefix,
    worker_id,
    worker_type,
    dockerfile,
    jobs=5,
    save_packages=False,
    shm_size="15G",
):
    name, instance = createWorker(
        worker_name_prefix,
        worker_id,
        worker_type,
        dockerfile,
        jobs,
        save_packages,
        shm_size,
        worker_name_suffix="-galera",
        volumes=[
            "/srv/buildbot/ccache:/mnt/ccache",
            "/srv/buildbot/packages:/mnt/packages",
            "/mnt/autofs/galera_packages/:/packages",
        ],
    )

    if name[0] not in workers:
        workers[name[0]] = [name[1]]
    else:
        workers[name[0]].append(name[1])

    c["workers"].append(instance)


for platform in all_platforms:
    jobs = None
    if platform == "amd64":
        machines = ["hz-bbw"]
        worker_ids = [1, 2, 4, 5]
        jobs = 7
    elif platform == "aarch64":
        machines = ["aarch64-bbw"]
        worker_ids = range(1, 6)
        jobs = 4
    elif platform == "ppc64le":
        machines = ["ppc64le-db-bbw"]
        worker_ids = [1]
        jobs = 12
    elif platform == "s390x":
        machines = ["s390x-bbw"]
        worker_ids = range(1, 3)
        jobs = 8
    elif platform == "x86":
        machines = ["hz-bbw"]
        worker_ids = [2]
        jobs = 7

    assert jobs is not None

    for w_name in machines:
        for i in worker_ids:
            for os_str in os_info:
                if platform in os_info[os_str]["arch"]:
                    quay_name = "quay.io/mariadb-foundation/bb-worker:" + "".join(
                        os_str.split("-")
                    )
                    os_name = os_str
                    if "ubuntu" in quay_name:
                        quay_name = quay_name[:-2] + "." + quay_name[-2:]
                    if platform == "x86":
                        quay_name += "-386"
                        os_name += "-i386"
                    addWorker(
                        w_name,
                        i,
                        "-" + os_name,
                        quay_name,
                        jobs=jobs,
                        save_packages=True,
                    )


def dpkgDeb():
    return ShellCommand(
        name="dpkg-scanpackages/sources",
        haltOnFailure=True,
        command=[
            "sh",
            "-xc",
            util.Interpolate(
                """set -e
    mkdir -p debs
    find .. -maxdepth 1 -type f -exec cp {} debs/ \;
    cd debs
    ( dpkg-scanpackages . /dev/null && dpkg-scanpackages --type ddeb . /dev/null  )| gzip -9c > Packages.gz
    dpkg-scansources . /dev/null | gzip -9c > Sources.gz
    cd ..
    find debs -type f -exec sha256sum {} \; | sort > sha256sums.txt
"""
            ),
        ],
        doStepIf=lambda step: savePackage(step, savedPackageBranches),
    )


def rpmSave():
    return ShellCommand(
        name="move rpm files",
        haltOnFailure=True,
        command=[
            "sh",
            "-xc",
            util.Interpolate(
                """set -e
    mkdir -p rpms srpms
    cp `find *.rpm -maxdepth 1 -type f` rpms
    find rpms -type f -exec sha256sum {} \; | sort > sha256sums.txt
"""
            ),
        ],
        doStepIf=lambda step: savePackage(step, savedPackageBranches),
    )


####### FACTORY CODE

## f_deb_build - create source tarball
f_deb_build = util.BuildFactory()
f_deb_build.addStep(
    steps.ShellCommand(command=["echo", " revision: ", util.Property("revision")])
)
f_deb_build.addStep(
    steps.GitHub(
        repourl=util.Property("repository"),
        mode="full",
        method="clobber",
        workdir="build",
        submodules=True,
    )
)
f_deb_build.addStep(
    steps.ShellCommand(
        name="build packages",
        command=[
            "bash",
            "-xc",
            util.Interpolate(
                """set -e
./scripts/build.sh -p"""
            ),
        ],
        workdir="build",
        env={"DEBIAN": "1"},
    )
)
f_deb_build.addStep(dpkgDeb())
f_deb_build.addStep(
    steps.ShellCommand(
        name="save_packages",
        timeout=7200,
        haltOnFailure=True,
        command=util.Interpolate(
            """
        source /etc/os-release; \
        mkdir -p /packages/%(prop:branch)s/%(prop:revision)s/%(prop:buildername)s \
        && cp -r debs/ sha256sums.txt /packages/%(prop:branch)s/%(prop:revision)s/%(prop:buildername)s/ \
        && cat << EOF > /packages/%(prop:branch)s/%(prop:revision)s/%(prop:buildername)s/galera.sources \
X-Repolib-Name: Galera
Types: deb
URIs: %(kw:url)s/%(prop:branch)s/%(prop:revision)s/%(prop:buildername)s
Suites: $VERSION_CODENAME
Components: main main/debug
Trusted: yes
EOF
        && ln -s %(prop:branch)s/%(prop:revision)s/%(prop:buildername)s/galera.sources /packages/%(prop:branch)s-latest-%(prop:buildername)s.sources \
        && sync /packages/%(prop:branch)s/%(prop:revision)s
""",
            url=os.getenv("ARTIFACTS_URL", default="https://ci.mariadb.org"),
        ),
        doStepIf=lambda step: savePackage(step, savedPackageBranches),
    )
)
f_deb_build.addStep(
    steps.ShellCommand(
        name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True
    )
)

## f_rpm_build - create source tarball
f_rpm_build = util.BuildFactory()
f_rpm_build.addStep(
    steps.ShellCommand(command=["echo", " revision: ", util.Property("revision")])
)
f_rpm_build.addStep(
    steps.GitHub(
        repourl=util.Property("repository"),
        mode="full",
        method="clobber",
        workdir="build",
        submodules=True,
    )
)
f_rpm_build.addStep(
    steps.ShellCommand(
        name="build packages",
        command=["bash", "-xc", "./scripts/build.sh -p"],
        workdir="build",
    )
)
f_rpm_build.addStep(rpmSave())
f_rpm_build.addStep(
    steps.ShellCommand(
        name="save_packages",
        timeout=7200,
        haltOnFailure=True,
        command=util.Interpolate(
            """
        mkdir -p /packages/%(prop:branch)s/%(prop:revision)s/%(prop:buildername)s \
        cat << EOF > packages/%(prop:branch)s/%(prop:revision)s/%(prop:buildername)s/galera.repo
[Galera-%(prop:branch)s]
name=Galera %(prop:branch)s repo (build %(prop:tarbuildnum)s)
baseurl=%(kw:url)s/%(prop:branch)s/%(prop:revision)s/%(prop:buildername)s/rpms
gpgcheck=0
EOF
        && cp -r rpms srpms sha256sums.txt /packages/%(prop:branch)s/%(prop:revision)s/%(prop:buildername)s/ \
        && ln -sf %(prop:branch)s/%(prop:revision)s/%(prop:buildername)s/galera.repo /packages/%(prop:branch)s-latest-%(prop:buildername)s.repo \
        && sync /packages/%(prop:branch)s/%(prop:revision)s
""",
            url=os.getenv("ARTIFACTS_URL", default="https://ci.mariadb.org"),
        ),
        doStepIf=lambda step: savePackage(step, savedPackageBranches),
    )
)
f_rpm_build.addStep(
    steps.ShellCommand(
        name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True
    )
)

####### BUILDERS LIST
c["builders"] = []

for os_i in os_info:
    for arch in os_info[os_i]["arch"]:
        builder_name = "gal-" + arch + "-" + os_i

        assert builder_name in builders_galera

        worker_name = arch + "-bbw-docker-" + os_i
        if arch == "amd64":
            worker_name = "x64-bbw-docker-" + os_i
        if arch == "x86":
            worker_name = "x64-bbw-docker-" + os_i + "-i386"

        if os_info[os_i]["type"] == "rpm":
            factory = f_rpm_build
        else:
            factory = f_deb_build

        env = {}
        if os == "ubuntu-2004":
            print("using gcc/++-10")
            env = {"CC": "gcc-10", "CXX": "g++10"}

        c["builders"].append(
            util.BuilderConfig(
                name=builder_name,
                workernames=workers[worker_name],
                tags=[os_i, "galera", "gcc"],
                collapseRequests=True,
                nextBuild=nextBuild,
                env=env,
                factory=factory,
            )
        )

c["logEncoding"] = "utf-8"

c["multiMaster"] = True

c["mq"] = {  # Need to enable multimaster aware mq. Wamp is the only option for now.
    "type": "wamp",
    "router_url": os.getenv("MQ_ROUTER_URL", default="ws://localhost:8085/ws"),
    "realm": "realm1",
    # valid are: none, critical, error, warn, info, debug, trace
    "wamp_debug_level": "info",
}
