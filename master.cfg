# -*- python -*-
# ex: set filetype=python:

from buildbot.plugins import *
from buildbot.process.properties import Property, Properties
from buildbot.steps.shell import ShellCommand, Compile, Test, SetPropertyFromCommand
from buildbot.steps.mtrlogobserver import MTR, MtrLogObserver
from buildbot.steps.source.github import GitHub
from buildbot.process.remotecommand import RemoteCommand
from datetime import timedelta
from twisted.internet import defer

import docker
import os
import sys

sys.setrecursionlimit(10000)

sys.path.insert(0, "/srv/buildbot/master")

from common_factories import *
from constants import *
from locks import *
from schedulers_definition import *
from utils import *

with open("master-config.yaml", "r") as f:
    master_config = yaml.safe_load(f)

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

# Load the slave, database passwords and 3rd-party tokens from an external private file, so
# that the rest of the configuration can be public.
config = {"private": {}}
exec(open("master-private.cfg").read(), config, {})

####### BUILDBOT SERVICES

# 'services' is a list of BuildbotService items like reporter targets. The
# status of each build will be pushed to these targets. buildbot/reporters/*.py
# has a variety to choose from, like IRC bots.


c["services"] = []
context = util.Interpolate("buildbot/%(prop:buildername)s")
gs = reporters.GitHubStatusPush(
    token=config["private"]["gh_mdbci"]["access_token"],
    context=context,
    startDescription="Build started.",
    endDescription="Build done.",
    verbose=True,
    builders=github_status_builders,
)
c["services"].append(gs)

####### PROJECT IDENTITY

# the 'title' string will appear at the top of this buildbot installation's
# home pages (linked to the 'titleURL').
c["title"] = os.getenv("TITLE", default="MariaDB CI")
c["titleURL"] = os.getenv("TITLE_URL", default="https://github.com/MariaDB/server")

# the 'buildbotURL' string should point to the location where the buildbot's
# internal web server is visible. This typically uses the port number set in
# the 'www' entry below, but with an externally-visible host name which the
# buildbot cannot figure out without some help.
c["buildbotURL"] = os.getenv("BUILDMASTER_URL", default="https://buildbot.mariadb.org/")

# 'protocols' contains information about protocols which master will use for
# communicating with workers. You must define at least 'port' option that workers
# could connect to your master with this protocol.
# 'port' must match the value configured into the workers (with their
# --master option)
c["protocols"] = {"pb": {"port": os.getenv("PORT", default=master_config["port"])}}

####### DB URL

c["db"] = {
    # This specifies what database buildbot uses to store its state.
    "db_url": config["private"]["db_url"]
}

mtrDbPool = util.EqConnectionPool(
    "MySQLdb",
    config["private"]["db_host"],
    config["private"]["db_user"],
    config["private"]["db_password"],
    config["private"]["db_mtr_db"],
)

####### Disable net usage reports from being sent to buildbot.net
c["buildbotNetUsageData"] = None

####### SCHEDULERS

# Configure the Schedulers, which decide how to react to incoming changes.
c["schedulers"] = getSchedulers()

####### WORKERS

# The 'workers' list defines the set of recognized workers. Each element is
# a Worker object, specifying a unique worker name and password.  The same
# worker name and password must be configured on the worker.
c["workers"] = []

# Docker workers

workers = {}


def addWorker(
    worker_name_prefix,
    worker_id,
    worker_type,
    dockerfile,
    jobs=5,
    save_packages=False,
    shm_size="15G",
):
    name, instance = createWorker(
        worker_name_prefix,
        worker_id,
        worker_type,
        dockerfile,
        jobs,
        save_packages,
        shm_size,
    )

    if name[0] not in workers:
        workers[name[0]] = [name[1]]
    else:
        workers[name[0]].append(name[1])

    c["workers"].append(instance)


for w_name in master_config["workers"]:
    jobs = 7

    for builder in master_config["builders"]:
        worker_name = w_name[:-1]
        worker_id = w_name[-1]

        os_name = "-".join(builder.split("-")[1:])
        image_tag = "".join(os_name.split("-"))

        # Skip s390x non-SLES builders on SLES host (bbw2)
        if ("s390x" in builder) and (worker_id == "2") and ("sles" not in os_name):
            continue

        if image_tag.startswith("ubuntu"):
            image_tag = image_tag[:-2] + "." + image_tag[-2:]

        quay_name = "quay.io/mariadb-foundation/bb-worker:" + image_tag
        if builder.startswith("x86"):
            os_name += "-i386"
            quay_name += "-386"
        addWorker(
            worker_name,
            worker_id,
            "-" + os_name,
            quay_name,
            jobs=jobs,
            save_packages=True,
        )

####### FACTORY CODE

f_quick_build = getQuickBuildFactory('nm', mtrDbPool)
f_rpm_autobake = getRpmAutobakeFactory(mtrDbPool)

## f_deb_autobake
f_deb_autobake = util.BuildFactory()
f_deb_autobake.addStep(
    steps.ShellCommand(
        name="Environment details",
        command=["bash", "-c", "date -u && uname -a && ulimit -a"],
    )
)
f_deb_autobake.addStep(
    steps.SetProperty(
        property="dockerfile",
        value=util.Interpolate("%(kw:url)s", url=dockerfile),
        description="dockerfile",
    )
)
f_deb_autobake.addStep(downloadSourceTarball())
f_deb_autobake.addStep(
    steps.ShellCommand(
        command=util.Interpolate(
            "tar -xzf ./packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1"
        )
    )
)
# build steps
f_deb_autobake.addStep(
    steps.Compile(
        logfiles={"CMakeCache.txt": "./builddir/CMakeCache.txt"},
        command=["debian/autobake-deb.sh"],
        env={
            "CCACHE_DIR": "/mnt/ccache",
            "DEB_BUILD_OPTIONS": util.Interpolate(
                "parallel=%(kw:jobs)s",
                jobs=util.Property("jobs", default="$(getconf _NPROCESSORS_ONLN)"),
            ),
        },
        description="autobake-deb.sh",
    )
)
# upload artifacts
f_deb_autobake.addStep(
    steps.SetPropertyFromCommand(
        command="find .. -maxdepth 1 -type f", extract_fn=ls2string
    )
)
f_deb_autobake.addStep(createDebRepo())
f_deb_autobake.addStep(uploadDebArtifacts())

f_deb_autobake.addStep(
    steps.Trigger(
        name="dockerlibrary",
        schedulerNames=["s_dockerlibrary"],
        waitForFinish=False,
        updateSourceStamp=False,
        set_properties={
            "tarbuildnum": Property("tarbuildnum"),
            "mariadb_version": Property("mariadb_version"),
            "master_branch": Property("master_branch"),
            "parentbuildername": Property("buildername"),
        },
        doStepIf=lambda step: hasDockerLibrary(step),
    )
)
f_deb_autobake.addStep(
    steps.Trigger(
        name="release preparation",
        schedulerNames=["s_release_prep"],
        waitForFinish=True,
        updateSourceStamp=False,
        set_properties={
            "tarbuildnum": Property("tarbuildnum"),
            "mariadb_version": Property("mariadb_version"),
            "master_branch": Property("master_branch"),
            "parentbuildername": Property("buildername"),
        },
        doStepIf=lambda step: savePackage(step),
    )
)
f_deb_autobake.addStep(
    steps.Trigger(
        name="install",
        schedulerNames=["s_install"],
        waitForFinish=False,
        updateSourceStamp=False,
        set_properties={
            "tarbuildnum": Property("tarbuildnum"),
            "mariadb_version": Property("mariadb_version"),
            "master_branch": Property("master_branch"),
            "parentbuildername": Property("buildername"),
            "sst_mode": "off",
        },
        doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step),
    )
)
f_deb_autobake.addStep(
    steps.Trigger(
        name="galera-sst-mariabackup",
        schedulerNames=["s_install"],
        waitForFinish=False,
        updateSourceStamp=False,
        set_properties={
            "tarbuildnum": Property("tarbuildnum"),
            "mariadb_version": Property("mariadb_version"),
            "master_branch": Property("master_branch"),
            "parentbuildername": Property("buildername"),
            "sst_mode": "mariabackup",
        },
        doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step),
    )
)
f_deb_autobake.addStep(
    steps.Trigger(
        name="galera-sst-mysqldump",
        schedulerNames=["s_install"],
        waitForFinish=False,
        updateSourceStamp=False,
        set_properties={
            "tarbuildnum": Property("tarbuildnum"),
            "mariadb_version": Property("mariadb_version"),
            "master_branch": Property("master_branch"),
            "parentbuildername": Property("buildername"),
            "sst_mode": "mysqldump",
        },
        doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step),
    )
)
f_deb_autobake.addStep(
    steps.Trigger(
        name="galera-sst-rsync",
        schedulerNames=["s_install"],
        waitForFinish=False,
        updateSourceStamp=False,
        set_properties={
            "tarbuildnum": Property("tarbuildnum"),
            "mariadb_version": Property("mariadb_version"),
            "master_branch": Property("master_branch"),
            "parentbuildername": Property("buildername"),
            "sst_mode": "rsync",
        },
        doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step),
    )
)
f_deb_autobake.addStep(
    steps.Trigger(
        name="major-minor-upgrade",
        schedulerNames=["s_upgrade"],
        waitForFinish=False,
        updateSourceStamp=False,
        set_properties={
            "tarbuildnum": Property("tarbuildnum"),
            "mariadb_version": Property("mariadb_version"),
            "master_branch": Property("master_branch"),
            "parentbuildername": Property("buildername"),
        },
        doStepIf=lambda step: hasUpgrade(step) and savePackage(step) and hasFiles(step),
    )
)
f_deb_autobake.addStep(
    steps.ShellCommand(
        name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True
    )
)

####### BUILDERS LIST

c["builders"] = []

for builder in master_config["builders"]:
    splits = builder.split("-")
    arch = splits[0]
    os_name = "-".join(splits[1:])

    mtr_additional_args = None
    if "mtr_additional_args" in os_info[os_name]:
        if arch in os_info[os_name]["mtr_additional_args"]:
            mtr_additional_args = os_info[os_name]["mtr_additional_args"][arch]

    if arch == "amd64":
        arch = "x64"
    worker_name = arch + "-bbw-docker-" + os_name

    if arch == "x86":
        worker_name = "x64-bbw-docker-" + os_name + "-i386"

    build_type = os_info[os_name]["type"]

    # Add builder only if it's not a protected branches one
    if builder not in github_status_builders:
        c["builders"].append(
            util.BuilderConfig(
                name=builder,
                workernames=workers[worker_name],
                tags=[os_name],
                collapseRequests=True,
                nextBuild=nextBuild,
                canStartBuild=canStartBuild,
                locks=getLocks,
                factory=f_quick_build,
            )
        )

    factory_instance = f_deb_autobake
    properties = {}

    if arch == "ppc64le":
        properties["verbose_build"] = "VERBOSE=1"
    if mtr_additional_args is not None:
        properties["mtr_additional_args"] = mtr_additional_args
    if build_type == "rpm":
        properties["rpm_type"] = "".join(os_name.split("-"))
        factory_instance = f_rpm_autobake
    c["builders"].append(
        util.BuilderConfig(
            name=builder + "-" + build_type + "-autobake",
            workernames=workers[worker_name],
            tags=[os_name, build_type, "autobake"],
            collapseRequests=True,
            nextBuild=nextBuild,
            canStartBuild=canStartBuild,
            locks=getLocks,
            properties=properties,
            factory=factory_instance,
        )
    )

c["logEncoding"] = "utf-8"

c["multiMaster"] = True

c["mq"] = {  # Need to enable multimaster aware mq. Wamp is the only option for now.
    "type": "wamp",
    "router_url": os.getenv("MQ_ROUTER_URL", default="ws://localhost:8085/ws"),
    "realm": "realm1",
    # valid are: none, critical, error, warn, info, debug, trace
    "wamp_debug_level": "info",
}
